# txt2img Docker Compose Configuration
# Uses hdae/ai-base for consistent Python/uv environment

services:
  server:
    image: hdae/ai-base
    restart: unless-stopped
    ports:
      - "8000:8000"
    environment:
      - PUID=${PUID:-1000}
      - PGID=${PGID:-1000}
      - UV_CACHE_DIR=/workspace/.uv-cache
      - PYTHON_VERSION=${PYTHON_VERSION:-3.13}
      - SKIP_VCS=true
      # Model configuration (JSON string, URL, or preset path)
      - CONFIG=${CONFIG:-sdxl/illustrious}
      # API keys
      - CIVITAI_API_KEY=${CIVITAI_API_KEY:-}
      - HF_TOKEN=${HF_TOKEN:-}
      # VRAM optimization (full, balanced, lowvram)
      - VRAM_PROFILE=${VRAM_PROFILE:-full}
      # Output format (png, webp)
      - OUTPUT_FORMAT=${OUTPUT_FORMAT:-png}
      # Directories
      - MODEL_CACHE_DIR=/workspace/models
      - OUTPUT_DIR=/workspace/outputs
      - PRESETS_DIR=/workspace/app/presets
      # HuggingFace cache
      - HF_HOME=/workspace/.hf-cache
    volumes:
      # Persistent storage
      - server-data:/workspace

      # Cache volume (Shared)
      - uv-cache:/workspace/.uv-cache

      # Model cache (Shared)
      - model-cache:/workspace/models

      # HuggingFace cache (Shared)
      - hf-cache:/workspace/.hf-cache

      # Output directory (host mount)
      - ./outputs:/workspace/outputs

      # Startup script
      - ./start.sh:/start.sh

      # Source code (development mount)
      - ./server:/workspace/app

    tty: true
    security_opt:
      - no-new-privileges:true

    # GPU Support (Required for SDXL)
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]

    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s

volumes:
  server-data:
  model-cache:
  hf-cache:
  uv-cache:
    name: shared_uv-cache
    external: true
